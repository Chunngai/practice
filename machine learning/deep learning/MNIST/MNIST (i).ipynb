{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "DATA_ROOT = \"./data\"\n",
    "BATCH_SIZE = 6\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH_NUMBER = 10\n",
    "MODEL_PATH = \"./mnist_net.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a transformer.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads the dataset.\n",
    "trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "testset = torchvision.datasets.MNIST(root=\"./data\", train=False,transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates data loaders.\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a LeNet.\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)  # (i)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=400, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        z1 = self.conv1(inputs)\n",
    "        a1 = F.relu(z1)\n",
    "        a1 = F.max_pool2d(a1, 2)\n",
    "              \n",
    "        z2 = self.conv2(a1)\n",
    "        a2 = F.relu(z2)\n",
    "        a2 = F.max_pool2d(a2, 2)\n",
    "        a2 = a2.view(-1, 400)\n",
    "        \n",
    "        z3 = self.fc1(a2)\n",
    "        a3 = F.relu(z3)\n",
    "        \n",
    "        z4 = self.fc2(a3)\n",
    "        a4 = F.relu(z4)\n",
    "        \n",
    "        z5 = self.fc3(a4)\n",
    "        \n",
    "        return z5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    (i) The img size is 28 but the input size of LeNet is 32, thus padding is needed.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an object for the nn module.\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify the Criterion and Create an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses cross entropy as criterion.\n",
    "criterion = nn.CrossEntropyLoss()  # (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    (i) The outputs are of size [BATCH_SIZE, 10], whereas the labels are [BATCH_SIZE]. Modification is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses SGD as optim.\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1, times:  2000, loss: 1.1870577761756722\n",
      "epoch:  1, times:  4000, loss: 0.23506574567733332\n",
      "epoch:  1, times:  6000, loss: 0.15155215469530958\n",
      "epoch:  1, times:  8000, loss: 0.12621233039686194\n",
      "epoch:  1, times: 10000, loss: 0.11574725920433411\n",
      "epoch:  2, times:  2000, loss: 0.09064269549781238\n",
      "epoch:  2, times:  4000, loss: 0.07923866318311593\n",
      "epoch:  2, times:  6000, loss: 0.07732646262271374\n",
      "epoch:  2, times:  8000, loss: 0.07615156177741847\n",
      "epoch:  2, times: 10000, loss: 0.07274835567868468\n",
      "epoch:  3, times:  2000, loss: 0.05938030254223941\n",
      "epoch:  3, times:  4000, loss: 0.06541370966519344\n",
      "epoch:  3, times:  6000, loss: 0.0498236924357268\n",
      "epoch:  3, times:  8000, loss: 0.051806494077342904\n",
      "epoch:  3, times: 10000, loss: 0.05156350825688082\n",
      "epoch:  4, times:  2000, loss: 0.03884538826545668\n",
      "epoch:  4, times:  4000, loss: 0.04757294632136154\n",
      "epoch:  4, times:  6000, loss: 0.04005073353668649\n",
      "epoch:  4, times:  8000, loss: 0.040735335312816916\n",
      "epoch:  4, times: 10000, loss: 0.04235551759383281\n",
      "epoch:  5, times:  2000, loss: 0.02935574204161702\n",
      "epoch:  5, times:  4000, loss: 0.032962557823050076\n",
      "epoch:  5, times:  6000, loss: 0.037916455152934646\n",
      "epoch:  5, times:  8000, loss: 0.03297650222650874\n",
      "epoch:  5, times: 10000, loss: 0.03115993945975788\n",
      "epoch:  6, times:  2000, loss: 0.024267770936252417\n",
      "epoch:  6, times:  4000, loss: 0.02566983377720126\n",
      "epoch:  6, times:  6000, loss: 0.02610866506849328\n",
      "epoch:  6, times:  8000, loss: 0.03023507769440141\n",
      "epoch:  6, times: 10000, loss: 0.03035384441719327\n",
      "epoch:  7, times:  2000, loss: 0.019438253106634024\n",
      "epoch:  7, times:  4000, loss: 0.023124566177855542\n",
      "epoch:  7, times:  6000, loss: 0.024065759032406986\n",
      "epoch:  7, times:  8000, loss: 0.02442900280602717\n",
      "epoch:  7, times: 10000, loss: 0.027591493117275833\n",
      "epoch:  8, times:  2000, loss: 0.020703529547244286\n",
      "epoch:  8, times:  4000, loss: 0.01774502971606695\n",
      "epoch:  8, times:  6000, loss: 0.016837728435047248\n",
      "epoch:  8, times:  8000, loss: 0.02120736591382837\n",
      "epoch:  8, times: 10000, loss: 0.021896857712594454\n",
      "epoch:  9, times:  2000, loss: 0.01623768755096726\n",
      "epoch:  9, times:  4000, loss: 0.015407625850085952\n",
      "epoch:  9, times:  6000, loss: 0.016742631795204604\n",
      "epoch:  9, times:  8000, loss: 0.018299630924984534\n",
      "epoch:  9, times: 10000, loss: 0.020365920360862846\n",
      "epoch: 10, times:  2000, loss: 0.014574885228882006\n",
      "epoch: 10, times:  4000, loss: 0.01309860195832694\n",
      "epoch: 10, times:  6000, loss: 0.015371573996513416\n",
      "epoch: 10, times:  8000, loss: 0.01571135195538276\n",
      "epoch: 10, times: 10000, loss: 0.01524053182102364\n"
     ]
    }
   ],
   "source": [
    "# Uses mini-batch gd to train the model\n",
    "times_for_display = 2000\n",
    "for epoch in range(EPOCH_NUMBER):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward prop.\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Back prop.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updates params.\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()  # (i)\n",
    "        if i % times_for_display == times_for_display - 1:\n",
    "            print(f\"epoch: {epoch + 1:>2}, times: {i + 1:>5}, loss: {running_loss / times_for_display}\")  # (ii), (iii)\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    (i) Use item() to make a one-elem tensor to a scalar\n",
    "    <br/>\n",
    "    (ii) Indentation.\n",
    "    <br/>\n",
    "    (iii) running_loss / TIMES_FOR_DISPLAY\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.97 %\n",
      "\n",
      "Accuracy of 0 is 99.80 %\n",
      "Accuracy of 1 is 98.77 %\n",
      "Accuracy of 2 is 99.32 %\n",
      "Accuracy of 3 is 98.51 %\n",
      "Accuracy of 4 is 99.49 %\n",
      "Accuracy of 5 is 99.55 %\n",
      "Accuracy of 6 is 98.54 %\n",
      "Accuracy of 7 is 98.93 %\n",
      "Accuracy of 8 is 98.56 %\n",
      "Accuracy of 9 is 98.51 %\n"
     ]
    }
   ],
   "source": [
    "# Calculates the accuracy of the whole dataset and each digit\n",
    "correct = 0.0  # (i)\n",
    "total = 0.0\n",
    "\n",
    "class_correct = [0.0 for i in range(10)]\n",
    "class_total = [0.0 for i in range(10)]\n",
    "\n",
    "with torch.no_grad():  # (ii)\n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Gets predictions using the trained model\n",
    "        outputs = net(inputs)\n",
    "        _, predictions = torch.max(input=outputs, dim=1)  # (iii)\n",
    "\n",
    "        # Statistics.\n",
    "        correct += (predictions == labels).sum()\n",
    "        total += BATCH_SIZE\n",
    "\n",
    "        for i in range(labels.size()[0]):  # (iv)\n",
    "            label = labels[i]\n",
    "            class_correct[label] += (predictions == labels)[i].item()  # (v)\n",
    "            class_total[label] += 1\n",
    "    \n",
    "print(f\"Accuracy: {correct / total * 100:.2f} %\")\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(f\"Accuracy of {i} is {class_correct[i] / class_total[i] * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    (i) Use floats or doubles instead of Ints.\n",
    "    <br/>\n",
    "    (ii) Grads are not needed for testing, thus use no_grad().\n",
    "    <br/>\n",
    "    (iii) _, predictions, but not predictions, _. We need the indices here.\n",
    "    <br/>\n",
    "    (iv) Don't use: for i in range(BATCH_SIZE):\n",
    "    <br/>\n",
    "    (v) class_correct[labels[i]], not class_correct[i]\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the model to the currect dir.\n",
    "torch.save(net.state_dict(), MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
